{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c5e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.ko.examples import sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c9b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì• í”Œì´ ì˜êµ­ì˜ ìŠ¤íƒ€íŠ¸ì—…ì„ 10ì–µ ë‹¬ëŸ¬ì— ì¸ìˆ˜í•˜ëŠ” ê²ƒì„ ì•Œì•„ë³´ê³  ìˆë‹¤.\n",
      "ì• í”Œì´ NOUN dislocated\n",
      "ì˜êµ­ì˜ PROPN nmod\n",
      "ìŠ¤íƒ€íŠ¸ì—…ì„ ADV advcl\n",
      "10ì–µ NUM compound\n",
      "ë‹¬ëŸ¬ì— NOUN advcl\n",
      "ì¸ìˆ˜í•˜ëŠ” VERB acl\n",
      "ê²ƒì„ NOUN obj\n",
      "ì•Œì•„ë³´ê³  AUX ROOT\n",
      "ìˆë‹¤ AUX aux\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"ko_core_news_sm\")\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b5d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ko-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ko_core_news_sm-3.8.0/ko_core_news_sm-3.8.0-py3-none-any.whl (14.7 MB)\n",
      "     ---------------------------------------- 0.0/14.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 2.4/14.7 MB 13.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 8.1/14.7 MB 21.9 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 10.5/14.7 MB 24.2 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 10.5/14.7 MB 24.2 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 10.5/14.7 MB 24.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 12.8/14.7 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 14.7/14.7 MB 11.4 MB/s eta 0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ko_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ko_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66444a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.11\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(spacy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5f90c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Korean model loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"ko_core_news_lg\")\n",
    "    print(\"âœ… Korean model loaded\")\n",
    "except:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"âš ï¸ Korean model not found, using English\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c1a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"ì œ ì´ë¦„ì€ ê¹€ë¯¼ìˆ˜ ìº˜ë¦¬í¬ë‹ˆì•„ êµ¬ê¸€ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\" # use lemma to see root word\n",
    "doc = nlp(text) #process token, entities, POS\n",
    "\n",
    "type(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063aa3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì œ, ì´ë¦„ì€, ê¹€ë¯¼ìˆ˜, ìº˜ë¦¬í¬ë‹ˆì•„, êµ¬ê¸€, ì¼í•˜ê³ , ìˆìŠµë‹ˆë‹¤, .]\n"
     ]
    }
   ],
   "source": [
    "tokenized = list(doc)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18105b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Text     Lemma       POS       Tag       Dep     Shape  is alpha   is stop\n",
      "================================================================================\n",
      "         ì œ         ì œ      PRON       npp  compound         x      True     False\n",
      "       ì´ë¦„ì€      ì´ë¦„+ì€      NOUN   ncn+jxtdislocated       xxx      True     False\n",
      "       ê¹€ë¯¼ìˆ˜       ê¹€ë¯¼ìˆ˜     PROPN        nq  compound       xxx      True     False\n",
      "     ìº˜ë¦¬í¬ë‹ˆì•„     ìº˜ë¦¬í¬ë‹ˆì•„     PROPN        nq  compound      xxxx      True     False\n",
      "        êµ¬ê¸€        êµ¬ê¸€      NOUN       ncn      flat        xx      True     False\n",
      "       ì¼í•˜ê³      ì¼+í•˜+ê³       VERBncpa+xsv+ecx      ROOT       xxx      True     False\n",
      "      ìˆìŠµë‹ˆë‹¤     ìˆ+ìŠµë‹ˆë‹¤       AUX     px+ef       aux      xxxx      True     False\n",
      "         .         .     PUNCT        sf     punct         .     False     False\n"
     ]
    }
   ],
   "source": [
    "#pos tagging\n",
    "\n",
    "str_format = \"{:>10}\"*8\n",
    "print(str_format.format('Text', 'Lemma', 'POS', 'Tag', 'Dep', 'Shape', 'is alpha', 'is stop'))\n",
    "print(\"==\"*40)\n",
    "\n",
    "for token in doc:\n",
    "    print(str_format.format(token.text, token.lemma_, token.pos_, token.tag_, \n",
    "                            token.dep_, token.shape_, str(token.is_alpha), str(token.is_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f10b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "                Text                 NER\n",
      "========================================\n",
      "                 ê¹€ë¯¼ìˆ˜                  PS\n",
      "               ìº˜ë¦¬í¬ë‹ˆì•„                  LC\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*40)\n",
    "str_format = \"{:>20}\"*2\n",
    "print(str_format.format('Text', 'NER'))\n",
    "print(\"=\"*40)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(str_format.format(ent.lemma_, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5864ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ë°', 'ìˆ˜', 'ë§', 'ê·¸ë¦¬ê³ ', 'ìˆ', 'ê°€', 'í•˜', 'ìœ„í•˜', 'ì‚´', 'ì˜', 'ì´', 'ë§í•˜', 'ë…„', 'í•œ', 'ê·¸ë ‡', 'ì¢€', 'ë³´', 'ì–´ë–»', 'ë§', 'ì–´ë–¤', 'ë”', 'ê·¸ëŸ°', 'ë˜', 'ì•Š', 'ë•Œ', 'ë“±', 'ë“¤', 'ë²ˆ', 'í•˜ë‚˜', 'ê²ƒ', 'ê°™', 'ì ', 'ê·¸ëŸ¬ë‚˜', 'ì¼', 'í¬', 'ë‹¤ë¥¸', 'ì´ë ‡', 'ì£¼', 'ì›', 'ë‚˜', 'ë•Œë¬¸', 'ëª»í•˜', 'ë‘', 'ì—†', 'ê·¸', 'ì˜¤', 'ì•ˆ', 'ì‹œí‚¤', 'ë°›', 'ë˜', 'ì•„ë‹ˆ', 'ë†“', 'ì¢‹', 'ì§€', 'ì•Œ', 'ê·¸ëŸ¬', 'ê·¸ê²ƒ', 'ì‹¶'}\n"
     ]
    }
   ],
   "source": [
    "stopwords = spacy.lang.ko.stop_words.STOP_WORDS\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d140544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì œ, ì´ë¦„ì€, ê¹€ë¯¼ìˆ˜, ìº˜ë¦¬í¬ë‹ˆì•„, êµ¬ê¸€, ì¼í•˜ê³ , ìˆìŠµë‹ˆë‹¤, .]\n"
     ]
    }
   ],
   "source": [
    "filtered = []\n",
    "for word in doc:\n",
    "    if not word.is_stop:\n",
    "        filtered.append(word)\n",
    "\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d47a15cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œ\n",
      "ì´ë¦„ì€\n",
      "ê¹€ë¯¼ìˆ˜\n",
      "ìº˜ë¦¬í¬ë‹ˆì•„\n",
      "êµ¬ê¸€\n",
      "ì¼í•˜ê³ \n",
      "ìˆìŠµë‹ˆë‹¤\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7031d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¹€ë¯¼ìˆ˜ -> PS\n",
      "ìº˜ë¦¬í¬ë‹ˆì•„ -> LC\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, \"->\", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220c46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "[EN]\n",
    "John Smith is a senior software engineer at Orion Financial Group.\n",
    "His employee ID is OFG-2023-4481 and he works in the New York office.\n",
    "You may contact him at john.smith@orionfinance.com or +1-415-993-2211.\n",
    "\n",
    "[EN]\n",
    "The company uses AWS and Google Cloud to store customer transaction data.\n",
    "Access to the database is restricted to internal staff from the Risk Management team.\n",
    "\n",
    "[KR]\n",
    "ê¹€ë¯¼ìˆ˜ ëŒ€ë¦¬ëŠ” ì‚¼ì„±ì „ì ë°˜ë„ì²´ ì‚¬ì—…ë¶€ì—ì„œ ê·¼ë¬´í•˜ê³  ìˆìœ¼ë©°,\n",
    "ì‚¬ë²ˆì€ SE-778291ì´ê³  ì„œìš¸ ì„œì´ˆêµ¬ ì‚¬ë¬´ì‹¤ì—ì„œ ì¼í•˜ê³  ìˆë‹¤.\n",
    "ì´ë©”ì¼ì€ minsu.kim@samsung.comì´ë©° ê°œì¸ ì—°ë½ì²˜ëŠ” 010-2345-7788ì´ë‹¤.\n",
    "\n",
    "[KR]\n",
    "ë³¸ ë¬¸ì„œëŠ” ë‚´ë¶€ ê¸°ë°€ ìë£Œë¡œ, ê³ ê°ì˜ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë° ê¸ˆìœµ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆë‹¤.\n",
    "ì™¸ë¶€ ìœ ì¶œ ì‹œ ë²•ì  ì±…ì„ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcaf0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN                   | OG\n",
      "John Smith           | PS\n",
      "is                   | OG\n",
      "a                    | PS\n",
      "Financial            | OG\n",
      "employee             | OG\n",
      "is                   | OG\n",
      "New York             | OG\n",
      "+1-415-993           | QT\n",
      "uses                 | LC\n",
      "AWS and              | OG\n",
      "Access               | OG\n",
      "is                   | OG\n",
      "restricted           | OG\n",
      "Risk                 | OG\n",
      "KR                   | OG\n",
      "ê¹€ë¯¼ìˆ˜                  | PS\n",
      "ì‚¼ì„±ì „ì                 | OG\n",
      "SE-778291ì´ê³           | QT\n",
      "ì„œìš¸ ì„œì´ˆêµ¬ ì‚¬ë¬´ì‹¤ì—ì„œ         | LC\n",
      "minsu.kim@samsung.comì´ë©° | OG\n",
      "KR                   | OG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sample_text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<20} | {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430cfb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[CONFIDENTIAL]]\n",
      "[CONFIDENTIAL] [CONFIDENTIAL] [CONFIDENTIAL] senior softw[CONFIDENTIAL]re engineer [CONFIDENTIAL]t Orion Fin[CONFIDENTIAL]nci[CONFIDENTIAL]l Group.\n",
      "H[CONFIDENTIAL] [CONFIDENTIAL] ID [CONFIDENTIAL] OFG-2023-4481 [CONFIDENTIAL]nd he works in the [CONFIDENTIAL] office.\n",
      "You m[CONFIDENTIAL]y cont[CONFIDENTIAL]ct him [CONFIDENTIAL]t john.smith@orionfin[CONFIDENTIAL]nce.com or [CONFIDENTIAL]-2211.\n",
      "\n",
      "[[CONFIDENTIAL]]\n",
      "The comp[CONFIDENTIAL]ny [CONFIDENTIAL] AWS [CONFIDENTIAL]nd Google Cloud to store customer tr[CONFIDENTIAL]ns[CONFIDENTIAL]ction d[CONFIDENTIAL]t[CONFIDENTIAL].\n",
      "[CONFIDENTIAL] to the d[CONFIDENTIAL]t[CONFIDENTIAL]b[CONFIDENTIAL]se [CONFIDENTIAL] [CONFIDENTIAL] to intern[CONFIDENTIAL]l st[CONFIDENTIAL]ff from the R[CONFIDENTIAL]k M[CONFIDENTIAL]n[CONFIDENTIAL]gement te[CONFIDENTIAL]m.\n",
      "\n",
      "[[CONFIDENTIAL]]\n",
      "[CONFIDENTIAL] ëŒ€ë¦¬ëŠ” [CONFIDENTIAL] ë°˜ë„ì²´ ì‚¬ì—…ë¶€ì—ì„œ ê·¼ë¬´í•˜ê³  ìˆìœ¼ë©°,\n",
      "ì‚¬ë²ˆì€ [CONFIDENTIAL] [CONFIDENTIAL] ì¼í•˜ê³  ìˆë‹¤.\n",
      "ì´ë©”ì¼ì€ minsu.kim@s[CONFIDENTIAL]msung.comì´ë©° ê°œì¸ ì—°ë½ì²˜ëŠ” 010-2345-7788ì´ë‹¤.\n",
      "\n",
      "[[CONFIDENTIAL]]\n",
      "ë³¸ ë¬¸ì„œëŠ” ë‚´ë¶€ ê¸°ë°€ ìë£Œë¡œ, ê³ ê°ì˜ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë° ê¸ˆìœµ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆë‹¤.\n",
      "ì™¸ë¶€ ìœ ì¶œ ì‹œ ë²•ì  ì±…ì„ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masked_text = sample_text\n",
    "\n",
    "for ent in doc.ents:\n",
    "    masked_text = masked_text.replace(ent.text, \"[CONFIDENTIAL]\")\n",
    "\n",
    "print(masked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e505906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¡´ ìŠ¤ë¯¸ìŠ¤ì´ê³  PS\n",
      "ìº˜ë¦¬í¬ë‹ˆì•„ì˜ LC\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = [\n",
    "    {\"label\": \"ORG\", \"pattern\": \"êµ¬ê¸€\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"ì‚¼ì„±ì „ì\"},\n",
    "    {\"label\": \"GPE\", \"pattern\": \"ìº˜ë¦¬í¬ë‹ˆì•„\"},\n",
    "    {\"label\": \"GPE\", \"pattern\": \"ì„œìš¸\"},\n",
    "]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "textt = \"ì œ ì´ë¦„ì€ ì¡´ ìŠ¤ë¯¸ìŠ¤ì´ê³  ìº˜ë¦¬í¬ë‹ˆì•„ì˜ êµ¬ê¸€ì—ì„œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "doc = nlp(textt)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbe58e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¡´ ìŠ¤ë¯¸ìŠ¤ì´ê³  PS\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ko_core_news_sm\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = [\n",
    "    {\n",
    "        \"label\": \"ORG\",\n",
    "        \"pattern\": [{\"LEMMA\": \"êµ¬ê¸€\"}]\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [{\"LEMMA\": \"ìº˜ë¦¬í¬ë‹ˆì•„\"}]\n",
    "    }\n",
    "]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "text = \"ì œ ì´ë¦„ì€ ì¡´ ìŠ¤ë¯¸ìŠ¤ì´ê³  ìº˜ë¦¬í¬ë‹ˆì•„ì˜ êµ¬ê¸€ì—ì„œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4093a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytextrank\n",
      "  Downloading pytextrank-3.3.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: GitPython>=3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytextrank) (3.1.43)\n",
      "Collecting graphviz>=0.13 (from pytextrank)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting icecream>=2.1 (from pytextrank)\n",
      "  Downloading icecream-2.1.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: networkx>=2.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (3.3)\n",
      "Requirement already satisfied: pygments>=2.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytextrank) (2.15.1)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytextrank) (1.13.1)\n",
      "Requirement already satisfied: spacy>=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytextrank) (3.8.11)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from GitPython>=3.1->pytextrank) (4.0.7)\n",
      "Requirement already satisfied: colorama>=0.3.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from icecream>=2.1->pytextrank) (0.4.6)\n",
      "Collecting executing>=2.1.0 (from icecream>=2.1->pytextrank)\n",
      "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from icecream>=2.1->pytextrank) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (2.2.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy>=3.0->pytextrank) (24.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from asttokens>=2.0.1->icecream>=2.1->pytextrank) (1.16.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1->pytextrank) (4.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->networkx[default]>=2.6->pytextrank) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.4->networkx[default]>=2.6->pytextrank) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.4->networkx[default]>=2.6->pytextrank) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0->pytextrank) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0->pytextrank) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.0->pytextrank) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.0->pytextrank) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.0->pytextrank) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy>=3.0->pytextrank) (2.1.3)\n",
      "Downloading pytextrank-3.3.0-py3-none-any.whl (26 kB)\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Downloading icecream-2.1.9-py3-none-any.whl (16 kB)\n",
      "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "Installing collected packages: graphviz, executing, icecream, pytextrank\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 0.8.3\n",
      "    Uninstalling executing-0.8.3:\n",
      "      Successfully uninstalled executing-0.8.3\n",
      "Successfully installed executing-2.2.1 graphviz-0.21 icecream-2.1.9 pytextrank-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytextrank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95f883ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¡´ ìŠ¤ë¯¸ìŠ¤ì´ê³  0.10829168419118157\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "nlp = spacy.load(\"ko_core_news_sm\")\n",
    "nlp.add_pipe(\"textrank\")\n",
    "\n",
    "text = \"ì œ ì´ë¦„ì€ ì¡´ ìŠ¤ë¯¸ìŠ¤ì´ê³  ìº˜ë¦¬í¬ë‹ˆì•„ì˜ êµ¬ê¸€ì—ì„œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for phrase in doc._.phrases[:10]:\n",
    "    print(phrase.text, phrase.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaea82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì¡´ ìŠ¤ë¯¸ìŠ¤ì´ê³ ']\n"
     ]
    }
   ],
   "source": [
    "import pytextrank\n",
    "\n",
    "nlp = spacy.load(\"ko_core_news_sm\")\n",
    "\n",
    "# ğŸ”‘ THIS LINE IS REQUIRED \n",
    "nlp.add_pipe(\"textrank\")\n",
    "\n",
    "keywords_textrank = []\n",
    "keywords_textrank_rank = []\n",
    "for phrase in doc._.phrases[:10]:\n",
    "    keywords_textrank.append(phrase.text)\n",
    "    keywords_textrank_rank.append(phrase.rank)\n",
    "    \n",
    "print(keywords_textrank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d306a8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
